---
title: "pset3_steiner"
author: "erika steiner"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

In this problem set, we continue analyzing the FTP program, again
interpreting beliefs about the time limit as the treatment variable. The
goal will be to estimate the effect of a perceived time limit on
employment and welfare receipt, this time using a
difference-in-differences approach. All data and documentation can be
found on Canvas under Problem Set 1.

```{r setup, include=FALSE}

# load packages
library("haven")
library("tidyverse")
library("magrittr")
library('knitr')
library('kableExtra')
library("fixest")
library("broom")
library("did")
# library("plm")
# library("stringr")
# library("stargazer")
# library("ivreg")

# get rid of scientific notation
options(scipen=999)

# don't print code
knitr::opts_chunk$set(echo = FALSE)
```

```{r data set up, echo = FALSE}
# import admin data
ftp_ar <- read_dta("ftp_ar.dta")
# import survey data
ftp_srv <- read_dta("ftp_srv.dta")

# create merged data set
# add treatment dummy equal to perceived subject to time limit
ftp_merged <- 
  # admin data set
  ftp_ar %>% 
  # filter out ftp_ar participants who did not participate in the survey
  # using sampleid per data documentation page 13
  filter(.$sampleid %in% (ftp_srv$sampleid)) %>% 
  # add new treatment dummy TLyes
  mutate(TLyes = 
    case_when(
      # 1 if believed subject to time limit
      fmi2 == 1 ~ 1,
      # 0 if did not or were not sure if subject to time limit
      fmi2 == 2 ~ 0,
      fmi2 == 8 ~ 0
    )
  ) %>% 
  # remove rows where TLyes = NA
  filter(!is.na(TLyes)) %>% 
  # make the employment quarter columns more readable
  rename(bfr.q01 = emppq1, bfr.q02 = emppq2, bfr.q03 = emppq3, bfr.q04 = emppq4, bfr.q05 = emppq5, bfr.q06 = emppq6, bfr.q07 = emppq7, bfr.q08 = emppq8, bfr.q09 = emppq9, bfr.q10 = emppq10, postr.q00 = empq1, postr.q01 = empq2, postr.q02 = empq3, postr.q03 = empq4, postr.q04 = empq5, postr.q05 = empq6, postr.q06 = empq7, postr.q07 = empq8, postr.q08 = empq9, postr.q09 = empq10, postr.q10 = empq11, postr.q11 = empq12, postr.q12 = empq13, postr.q13 = empq14, postr.q14 = empq15, postr.q15 = empq16, postr.q16 = empq17, postr.q17 = empq18, postr.q18 = empq19, postr.q19 = empq20)
```

1.  *Find the means of quarterly employment for each quarter from 10
    quarters prior to RA to 19 quarters following RA (recall from the
    documentation that the quarter of random assignment, which would
    naturally be designated as quarter 0, is actually denoted as quarter
    1). Tabulate the number of observations that contribute to each of
    those means.*

```{r q1 mean employment, echo = FALSE}
# Find the means of quarterly employment for each quarter
ftp_merged %>% 
  # from 10 quarters prior to RA to 19 quarters following RA
  # remember that empq20 = quarter 19 because RA occurs in quarter 1
  select(c('bfr.q10':'postr.q16', 'postr.q17':'postr.q19')) %>% 
  # calculate the mean across selected columns
  summarise(across(everything(),
    # using list as we're doing multiple functions and want to give custom name to output col
    list(qemp_mean = ~ mean(.x, na.rm = TRUE),
         # and tabulating n used in means
         valid_n = ~ sum(!is.na(.x))
         )
    )) %>% 
  # make table readable
  pivot_longer(cols = everything(),
               # split quarter, mean, and n
               names_to = c("quarter", ".value"),
               # (.*) puts first part of string into quarter column
               # qemp_mean|valid_n selects values to pull for each new mean/n col
               names_pattern = "(.*)_(qemp_mean|valid_n)"
               ) %>% 
  # and pretty
  kable(col.names = c("Quarter", "Mean", "N"), caption = "Quarterly Employment Means") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"))

```

1.  *Continued: What is the longest pre-period that you could analyze,
    ensuring that you have data for everyone in the sample? The longest
    post-period? Refer to this as the balanced sample period.*

There are 1149 people who responded to the survey question about time
limits. All pre-randomization quarters include 1149 non-NA observations,
as do all post-randomization quarters except for Quarter 19 (postr.q19
aka empq20).The balanced sample period is thus from 10 quarters prior to
RA to 18 quarters following RA.

2.  *Reconfigure the data so you have one record per person per quarter.
    Compute mean employment rates by treatment status, before and after
    treatment. Treatment status is TLyes; the date of random assignment
    divides the sample period into before and after (consider the period
    of random assignment itself to be “after”).*

```{r q2 mean, echo = FALSE}
# reconfigure the data so you have one record per person per quarter
# create a balanced sample period (remove empq20)

quarter_levels <- c("bfr.q10","bfr.q09", "bfr.q08", "bfr.q07", "bfr.q06", "bfr.q05", "bfr.q04", "bfr.q03", "bfr.q02", "bfr.q01", "postr.q00", "postr.q01", "postr.q02", "postr.q03", "postr.q04", "postr.q05", "postr.q06", "postr.q07", "postr.q08", "postr.q09", "postr.q10", "postr.q11", "postr.q12", "postr.q13", "postr.q14", "postr.q15", "postr.q16", "postr.q17", "postr.q18", "postr.q19")

qemp_rates <- ftp_merged %>% 
  # select columns needed for analyses, such as treatment status
  select(c("TLyes", 
           # employment quarters for balanced sample period only
           'bfr.q10':'postr.q16', 'postr.q17':'postr.q18')
         ) %>% 
  # pivot longer for easier manipulation
  pivot_longer(cols = -TLyes,
               names_to = "quarter",
               values_to = "employment") %>% 
  # convert quarter to factor for better ordering
  # group by treatment status and quarter
  group_by(TLyes, quarter) %>% 
  # calculate means for each treatment group and quarter
  summarise(mean = mean(employment, na.rm = TRUE),
            n = sum(!is.na(employment)),
            # ungroup
            .groups = "drop") %>% 
  # make table readable
  pivot_wider(names_from = TLyes,
              values_from = c(mean, n)) 

qemp_rates %>% 
  # factor quarters for ordering
  mutate(quarter = factor(quarter, levels = quarter_levels)) %>% 
  arrange(quarter) %>% 
  kable(col.names = c("Quarter", "Control Mean", "Treatment Mean", "Control N", "Treatment N"), 
        caption = "Quarterly Employment by Treatment Status") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"))


```

2\. *Continued: Were employment rates similar between the treatment and
control groups prior to treatment?*

Prior to treatment (emppq10:emppq1), the employment rates between the
treatment and control groups are similar. If we run a two-sample t-test,
as done below, we cannot reject the null hypothesis that the true
difference in means between the treatment and control groups is equal to
0.

```{r t-testing pre-emp, echo = FALSE}
ttest_df <- ftp_merged %>% 
  # select columns needed for analyses, such as treatment status
  select(c("TLyes", 
           # employment quarters for pre-randomization only
           'bfr.q10':'bfr.q01')
         ) %>% 
  # pivot longer for easier manipulation
  pivot_longer(cols = -TLyes,
               names_to = "quarter",
               values_to = "employment") %>% 
  # convert quarter to factor for better ordering
  # group by treatment status and quarter
  group_by(TLyes, quarter) %>% 
  # calculate means for each treatment group and quarter
  summarise(pre_mean = mean(employment, na.rm = TRUE),
            n = sum(!is.na(employment)),
            # ungroup
            .groups = "drop")

t.test(pre_mean ~ TLyes, data = ttest_df)
```

3.  *(a) Run a DD regression. The dependent variable should be quarterly
    employment status, and the explanatory variables should include
    person dummies, quarter dummies, and an interaction between TLyes
    and a post-treatment dummy. Be sure to restrict attention to the
    balanced sample period.*

```{r 3a DD regression, echo = FALSE}
dd3a_data <- ftp_merged %>% 
  # select relevant columns
  select(c(
    # sampleid
    "sampleid",
    # treatment status
    "TLyes",
    # quarterly employment status for balanced sample period
    'bfr.q10':'postr.q16', 'postr.q17':'postr.q18'),
    # columns of person dummies/covariates
    # method pulled from pset 1
    where(~ {
    # the column's label
    column_label <- attributes(.)$label
    # is not null AND contains 'cova' (returns TRUE)
    !is.null(column_label) && str_detect(column_label, 'cova')
    })) %>% 
  # reshape to long format so quarter employment values change over time
  pivot_longer(bfr.q10:postr.q18,
    names_to = "quarter",
    values_to = "employment_status"
  ) %>% 
  # add post-treatment dummy
  mutate(post_dummy = case_when(
    grepl("bfr", quarter) ~ 0,
    grepl("post", quarter) ~ 1
  )) 
  
# run a fixed-effects OLS regression
model3a <- feols(employment_status ~ TLyes * post_dummy | sampleid + quarter, data = dd3a_data)

summary(model3a, 
        # specify non-clustered errors as feols auto clusters on sampleid
        se = "hetero")
```

3.  *(b) Now run the same regression, clustering the standard errors by
    sampleid*

```{r 3b standard errors, echo = FALSE}
model3b <- feols(
  # outcome: employment status
  employment_status ~ 
    # regressed on interaction of treatment and post dummy
    (TLyes * post_dummy) | 
    # controlling for sampleid (individual fixed effects, as these are time-invariant for each person) 
    sampleid 
  # and controlling for quarter (time-specific fixed effects)
  + quarter, 
  # use proper data set
  data = dd3a_data,
  # cluster standard errors by sampleid
  cluster = ~sampleid
  )

summary(model3b)
```

3.  *(b) Continued: Explain why the standard errors change the way they
    do. Which standard errors should you report?*

The standard errors increase (from 0.00849 to 0.018376) from the first
model (no clustering) to the second (clustered on sampleid). The
original model examines standard error for each observation of each
individual, suggesting artificial independence of each standard error,
even though the standard errors of observations are likely to be
correlated for each individual (sampleid). Clustering thus allows us to
control for this correlation by grouping observations by individual,
creating a more accurate calculation of the standard errors of the
model. Mathematically, we also know that standard error is inversely
proportional to the number of samples. By decreasing number of samples
(grouping by sampleid), we increase standard error.

3.  *(c) How do you interpret the coefficient on the interaction between
    TLyes and the post- treatment dummy?*

This coefficient (0.056039) says that treated individuals, following
treatment, were 5.6 percentage points more likely to be employed than
non-treated individuals in the same time period. The p-value of 0.002
(\>0.01) suggests that this change is highly statistically significant.

4.  *(a) Construct a test for parallel pre-treatment trends.*

```{r 4a parallel, echo = FALSE}
dd4a_data <- dd3a_data %>% 
  # only include pre-treatment period
  filter(post_dummy == 0) %>% 
  mutate(quarter = factor(quarter))

model4a <- feols(employment_status ~ (TLyes * quarter) | sampleid + quarter, data = dd4a_data)

summary(model4a)

```

4.  *(a) Continued: Do you reject the null hypothesis?* 

No! The coefficients of the interactions between the time effects and treatment status are not statistically significant.


4.  *(b) Plot the relevant results.*

```{r 4b plot, echo = FALSE}
# plot quarterly employment rates prior to randomization
d_cols <- c("darkorange", "cyan")
r_cols <- c("darkorange4", "cyan4")

dd4a_data %>% 
  select(c("TLyes", "quarter", "employment_status")) %>% 
  mutate(quarter = factor(quarter, levels = quarter_levels),
           TLyes = case_when(
             TLyes == 0 ~ "control",
             TLyes == 1 ~ "treated"
             )) %>% 
  group_by(quarter, TLyes) %>% 
  summarise(mean = mean(employment_status),
                 sd = sd(employment_status),
                 se = sd / sqrt(n()), .groups = "keep") %>% 
  ggplot(aes(x = quarter, y = mean, color = as.factor(TLyes), group = as.factor(TLyes))) +
  geom_line()+
  geom_point() +
  geom_ribbon(aes(ymin = mean - (2*se), ymax = mean + (2*se)), alpha = 0.2) +
  scale_color_manual(values = d_cols) +
  labs(title = "Mean Employment Pre-Randomization by Treatment Status",
       x = "Quarter Pre-Randomization",
       y = "Mean Employment",
       color = "Treatment Status",
       caption = "* Ribbons capture range 2 standard errors away from mean. \n The complete overlap suggests no statistically significant difference between groups.") +
  theme_minimal()

# plot confidence interval and point estimate
coefplot(model4a,
         order = c("10", "09", "08", "07", "06", "05", "04", "03", "02"),
         xlab = "Quarter Before Treatment",
         ylab = "Interaction coeff. and 95% CI",
         main = "Treatment status impact on employment: Pre-treatment")

```

4.  *(c) Do your results imply that your estimator identifies the ATT?*

No, these results do not imply that the estimator identifies the ATT.
Identification of the ATT requires that there are parallel trends in the
untreated outcomes across the entire sample period. However, we cannot
know what the untreated outcomes would be for the treated group, as
there are no data on the counter-factual.

Failing parallel pre-trends would suggest the identifying assumption
fails, but passing (as we have in this case) does not imply that it
holds.

5.  *Now implement the event-study estimator, that is, estimate
    period-specific treatment effects that vary freely over the
    post-treatment period.*
    
```{r 5 event-study}
# implementing the event-study estimator
dd5_data <- dd3a_data %>% 
  # add a variable that identifies the number of periods after treatment
  mutate(trt_period = case_when(
    quarter == "bfr.q10" ~ -10,
    quarter == "bfr.q09" ~ -9,
    quarter == "bfr.q08" ~ -8,
    quarter == "bfr.q07" ~ -7,
    quarter == "bfr.q06" ~ -6,
    quarter == "bfr.q05" ~ -5,
    quarter == "bfr.q04" ~ -4,
    quarter == "bfr.q03" ~ -3,
    quarter == "bfr.q02" ~ -2,
    quarter == "bfr.q01" ~ -1,
    quarter == "postr.q00" ~ 0,
    quarter == "postr.q01" ~ 1,
    quarter == "postr.q02" ~ 2,
    quarter == "postr.q03" ~ 3,
    quarter == "postr.q04" ~ 4,
    quarter == "postr.q05" ~ 5,
    quarter == "postr.q06" ~ 6,
    quarter == "postr.q07" ~ 7,
    quarter == "postr.q08" ~ 8,
    quarter == "postr.q09" ~ 9,
    quarter == "postr.q10" ~ 10,
    quarter == "postr.q11" ~ 11,
    quarter == "postr.q12" ~ 12,
    quarter == "postr.q13" ~ 13,
    quarter == "postr.q14" ~ 14,
    quarter == "postr.q15" ~ 15,
    quarter == "postr.q16" ~ 16,
    quarter == "postr.q17" ~ 17,
    quarter == "postr.q18" ~ 18,
  ))

model5 <- feols(employment_status ~ 
                  # using i as we are examining the interaction between a categorical variable (trt_period) and a continuous variable (TLyes), setting baseline to right before treatment (-1)
                  i(trt_period, TLyes, ref = -1) | sampleid + quarter, data = dd5_data)

summary(model5)
```
5. *Continued: Plot the estimates.*
```{r 5 plot}
# plot model 5 estimates
# use iplot because we used i() in feols
iplot(model5,
      # add labels
       xlab = "Treatment Period",
      ylab = "Interaction coeff. and 95% CI",
         main = "Treatment-status impact on employment by period")
```


5. *Continued: Are the period-specific estimates significant? If not, does this concern you? Explain.*

Some of the period-specific estimates are significant. Period 8 is significant at the 0.01 level; periods 9, 12, and 13 are significant at the 0.05 level; periods 2, 3, 6, 7, 11, and 15 are significant the 0.1 level.

Importantly, none of the pre-treatment periods are significant; this confirms the pre-treatment parallel trend assumption holds. 

While we might expect that some of the periods have slightly larger or smaller coefficients (and thus differ in their significance), it is interesting to note that most of the significant treatment/period interactions occur between 6 and 13 quarters after treatment (peaking at quarter 8). This suggests that there is variance in treatment effect over time, particularly decreasing after period 13.

6.  *Compare the mean of the period-specific treatment effects from
    question 5 to the constant post-treatment effect from question 3.*
    
```{r 6 means}
# period-specific treatment effects from question 5
m5data <- tidy(model5) %>% 
  # exclude periods prior to treatment
  filter(!grepl("-", term))

# overall treatment effects from question 3
m3data <- tidy(model3b)

# print table of means
data.frame(
  model = c("3", "5"),
  mean = c((mean(m3data$estimate)), (mean(m5data$estimate)))) %>% 
  kable(col.names = c("Model", "Mean Effect"), 
        caption = "Mean Treatment Effect by Model") %>% 
  kable_styling(bootstrap_options = c("striped", "hover"))
  
```
6. *Continued: Are they similar? How would you test the hypothesis that they are
    the same?*
These mean effects do appear to be very similar. I would conduct the Wald test for pre-test of parallel trends.

7.  *So far, we have acted as if all the treatment observations were
    treated at the same calendar time. In fact, treatment was assigned
    over a period of four quarters, as can be seen by tabulating the
    variable rarelqt. Explain briefly why this potentially poses a
    problem for the analysis above.*

```{r 7 tab}
table(ftp_merged$rarelqt)
```

We know that treatment effects are heterogenous across units and time. Groups randomized into treatment at different quarters are thus experiencing different time effects at each "period" of measured employment. For example, if someone is randomized into treatment in Quarter 2 (approximately August 1994), their employment outcomes in period 8 (8 quarters after randomization) would include the treatment effect and time-specific effects of August 1996 (plus fixed individual effects which are irrelevant here). However the period 8 employment outcomes of someone randomized into treatment in Quarter 4 (approximately February 1995) would reflect the treatment effect and time-specific effects of February 1997. We cannot assume that the time-specific effects of August 1996 and February 1997 are the same; therefore, our analysis above does not accurately identify the average treatment effect. Rather, it conflates treatment effects with some time-specific influences. 


8.  *To see how important this issue is in practice, re-estimate your
    event-study model using the Callaway-Sant’anna method. Note that
    rarelqt = 1 corresponds to 1994.II, that is, April-June*

```{r 8 CS}
# using did package per https://rpubs.com/mbounthavong/cs_staggered_did_r

# creating data set, similar to 3a and 5 but with additional column
dd8_data <- ftp_merged %>% 
  # select relevant columns
  select(c(
    # sampleid
    "sampleid",
    # treatment status
    "TLyes",
    # quarterly employment status for balanced sample period
    'bfr.q10':'postr.q16', 'postr.q17':'postr.q18',
    # ADDED: COLUMN OF TREATMENT QUARTER
    "rarelqt"),
    # columns of person dummies/covariates
    # method pulled from pset 1
    where(~ {
    # the column's label
    column_label <- attributes(.)$label
    # is not null AND contains 'cova' (returns TRUE)
    !is.null(column_label) && str_detect(column_label, 'cova')
    })) %>% 
  # reshape to long format so quarter employment values change over time
  pivot_longer(bfr.q10:postr.q18,
    names_to = "quarter",
    values_to = "employment_status"
  ) %>% 
  # add post-treatment dummy
  mutate(post_dummy = case_when(
    grepl("bfr", quarter) ~ 0,
    grepl("post", quarter) ~ 1
  )) %>% 
  # CONVERT RARELQT to 0 IF NEVER TREATED
  mutate(rarelqt =
           case_when(
             TLyes == 0 ~ 0,
             TLyes == 1 ~ rarelqt
           )) %>%
  # add period variable
  mutate(trt_period = case_when(
    quarter == "bfr.q10" ~ -10,
    quarter == "bfr.q09" ~ -9,
    quarter == "bfr.q08" ~ -8,
    quarter == "bfr.q07" ~ -7,
    quarter == "bfr.q06" ~ -6,
    quarter == "bfr.q05" ~ -5,
    quarter == "bfr.q04" ~ -4,
    quarter == "bfr.q03" ~ -3,
    quarter == "bfr.q02" ~ -2,
    quarter == "bfr.q01" ~ -1,
    quarter == "postr.q00" ~ 0,
    quarter == "postr.q01" ~ 1,
    quarter == "postr.q02" ~ 2,
    quarter == "postr.q03" ~ 3,
    quarter == "postr.q04" ~ 4,
    quarter == "postr.q05" ~ 5,
    quarter == "postr.q06" ~ 6,
    quarter == "postr.q07" ~ 7,
    quarter == "postr.q08" ~ 8,
    quarter == "postr.q09" ~ 9,
    quarter == "postr.q10" ~ 10,
    quarter == "postr.q11" ~ 11,
    quarter == "postr.q12" ~ 12,
    quarter == "postr.q13" ~ 13,
    quarter == "postr.q14" ~ 14,
    quarter == "postr.q15" ~ 15,
    quarter == "postr.q16" ~ 16,
    quarter == "postr.q17" ~ 17,
    quarter == "postr.q18" ~ 18,
  )) %>% 
  # introduce absolute calendar quarter
   mutate(cal_quarter = 
            case_when(
# quarter treated - 1 (because treated at 1 will be starting in 0 period)
              TLyes == 1 ~  (rarelqt - 1) + trt_period,
              TLyes == 0 ~ trt_period
              )
  ) %>% 
  mutate(sampleid = as.numeric(as.factor(sampleid)))

att_gt(yname = "employment_status",
       tname = "cal_quarter",
       idname = "sampleid",
       gname = "rarelqt",
       data = dd8_data,
       est_method = "dr",
       control_group = "notyettreated",
       clustervars = "sampleid",
       panel = FALSE
         )

```

9.  *Start by creating a variable showing which observations are first
    treated in each calendar quarter. Call it racalqt. Tabulate it and
    comment on the share of observations that is first assigned to
    treatment in each quarter.*
```{r 9}
table9 <- dd8_data %>% 
  mutate(racalqt =
           case_when(
             rarelqt == 1 ~ "1994.II",
             rarelqt == 2 ~ "1994.III",
             rarelqt == 3 ~ "1994.IV",
             rarelqt == 4 ~ "1995.I",
             rarelqt == 0 ~ "Never Treated"
           )) %>% 
  count(racalqt)



table9 %>% 
  mutate(share = (n/(10614 + 13543 + 9164)))
```
    
24% of observations are assigned to treatment during the 4th quarter of 1994. 18% are assigned to treatment during the 3rd quarter of 1994, while only 16% are assigned to treatment during the 1st quarter of 1995. 42% are never assigned to treatment.

10. *Calculate ATT(g, t) for each value of g and t = 1994.II to 1997.II.
    How similar are the estimated effects of treatment for the four
    groups?*
    
```{r 10}

```
    

11. *Now calculate and plot period-specific treatment effects in units
    of time relative to the treatment quarter, also known as elapsed
    time and denoted by e. Do this for e=1,...,8.*
    
```{r 11}

```


12. *Compare these estimates to those you estimated in question 5. Would
    you say they are mostly similar, or mostly different? Pay particular
    attention to the estimates for e=1 to 4.*
    
```{r 12}

```

